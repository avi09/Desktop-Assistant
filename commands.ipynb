{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTuS5RI9mKn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import json\n",
        "\n",
        "def open1(s):\n",
        "\tflag = -1\n",
        "\ti = len(s) - 1\n",
        "\twhile i>-1 and flag==-1:\n",
        "\t\tif s[i]==' ' and flag==-1:\n",
        "\t\t\ts = s[i+1:]\n",
        "\t\t\tflag=1\n",
        "\t\telse:\n",
        "\t\t\ts1 = ''\n",
        "\t\ti = i - 1\n",
        "\tf = open('open.txt','r')\n",
        "\tx = f.readlines()\n",
        "\tf.close()\n",
        "\tfor i in x:\n",
        "\t\tif i.split('--__')[0] == s:\n",
        "\t\t\tos.system(i.split('--__')[1])\n",
        "\n",
        "def meaning(s):\n",
        "\tflag = -1\n",
        "\ti = len(s) - 1\n",
        "\twhile i>-1 and flag==-1:\n",
        "\t\tif s[i]==' ' and flag==-1:\n",
        "\t\t\ts = s[i+1:]\n",
        "\t\t\tflag = 1\n",
        "\t\telse:\n",
        "\t\t\ts1=''\n",
        "\t\ti = i -1\n",
        "\tf = json.load(open('data.json'))\n",
        "\tprint(f[s][0])\n",
        "\n",
        "def string_adjustment(s):\n",
        "\treturn s.lower()\n",
        "\t\n",
        "def command(s):\n",
        "  s = stem(x)\n",
        "\ts = string_adjustment(s)\n",
        "\tif s.find('command')!=-1:\n",
        "\t\tos.system(s[8:])\n",
        "\t\tf = open('1.txt','r')\n",
        "\t\tx=f.readlines()\n",
        "\t\trandom.shuffle(x)\n",
        "\t\treturn x[1]\n",
        "\t\n",
        "\telif s.find('meaning')!=-1:\n",
        "\t\tmeaning(s)\n",
        "\t\tf = open('1.txt','r')\n",
        "\t\tx = f.readlines()\n",
        "\t\trandom.shuffle(x)\n",
        "\t\treturn x[1]\n",
        "\t\t\n",
        "\telif s.find('open')!=-1 or s.find('launch')!=-1:\n",
        "\t\topen1(s)\n",
        "\t\tf = open('1.txt','r')\n",
        "\t\tx=f.readlines()\n",
        "\t\trandom.shuffle(x)\n",
        "\t\treturn x[1]\n",
        "\t\t\n",
        "\telif s.find('run')!=-1:\n",
        "\t\topen1(s)\n",
        "\t\tf = open('1.txt','r')\n",
        "\t\tx = f.readlines()\n",
        "\t\trandom.shuffle(x)\n",
        "\t\treturn x[1]\n",
        "\t\t\n",
        "\telse:\n",
        "\t\tf = open('2.txt','r')\n",
        "\t\tx=f.readlines()\n",
        "\t\trandom.shuffle(x)\n",
        "\t\treturn x[1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwMDRI2GnrDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem(s):\n",
        "  stem = PorterStemmer()\n",
        "  word_m = WordNetLemmatizer()\n",
        "\n",
        "  stopwords = ['of','and','can','please','for','hey','be','will','you']\n",
        "  x = s\n",
        "  xy=''\n",
        "  for i in x.split(' '):\n",
        "    if i in stopwords:\n",
        "      y=1\n",
        "    else:\n",
        "      xy+=i+' '\n",
        "  x=''\n",
        "  for i in xy.split(' '):\n",
        "    y=stem.stem(i)\n",
        "    y=word_m.lemmatize(y,'v')\n",
        "    x+=y+' '\n",
        "  return x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmoxSBYvuILE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUR9-z_kuIXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}